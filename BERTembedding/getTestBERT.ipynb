{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getTestBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PPWzIEMCWyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input files: test dataset or whole dataset,paragraphs file\n",
        "# ouput: Zip file containing testing dataset with selected paragraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFWrvC3hRSE",
        "colab_type": "code",
        "outputId": "9f25fe7f-02ca-4830-ca7a-c0d3c3149f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''!pip install tensorflow==2.0\n",
        "!pip install tensorflow_hub\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!pip install tensorflow==2.0\\n!pip install tensorflow_hub\\n!pip install bert-for-tf2\\n!pip install sentencepiece'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghxYM2BH9Vq6",
        "colab_type": "code",
        "outputId": "37f48edc-c197-4f63-a88f-c67baa96abc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.0.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Y0nbeK9Xl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
        "#import math\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7AlViAd9ahm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basePath = '/content/'\n",
        "\n",
        "'''data_dir = basePath+'dataset'\n",
        "drive_dir = basePath+'drive/My Drive/temp/DatasetN'\n",
        "paraFile = basePath + 'paragraph2.json' '''\n",
        "\n",
        "data_dir = basePath+'tempdataset'\n",
        "drive_dir = basePath+'drive/My Drive/temp/tempDataset'\n",
        "paraFile = basePath + 'temp.json'\n",
        "\n",
        "outDir = basePath+'test'\n",
        "\n",
        "max_seq_length = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9GmAOEr9hR5",
        "colab_type": "code",
        "outputId": "c9de6a28-3eb2-4545-db63-cd515227d609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''for file_name in os.listdir(drive_dir):\n",
        "    if file_name.endswith('.zip'):\n",
        "        with zipfile.ZipFile(drive_dir+'/'+file_name,'r') as zip_dir:\n",
        "            zip_dir.extractall(path='/content/')'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"for file_name in os.listdir(drive_dir):\\n    if file_name.endswith('.zip'):\\n        with zipfile.ZipFile(drive_dir+'/'+file_name,'r') as zip_dir:\\n            zip_dir.extractall(path='/content/')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL4bVRKh9jwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getBERTModel():\n",
        "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_mask\")\n",
        "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"segment_ids\")\n",
        "\n",
        "    bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=False)\n",
        "    #bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\",trainable=False)\n",
        "    \n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
        "\n",
        "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "    FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "    tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "    return {'model':model,'tokenizer':tokenizer}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTZ-xWWW9mHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_masks(tokens, max_seq_length):\n",
        "    #print('len(tokens),max_seq_length)\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbY_RPO9orm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getEmbeddings(model,tokenizer,sentence): \n",
        "    stokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    if len(stokens) > (max_seq_length - 2):\n",
        "      stokens = stokens[:max_seq_length-2]\n",
        "\n",
        "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
        "    #print(len(input_ids))\n",
        "    input_masks = get_masks(stokens, max_seq_length)\n",
        "    input_segments = get_segments(stokens, max_seq_length)\n",
        "\n",
        "    '''print(input_masks)\n",
        "    print(input_segments)'''\n",
        "\n",
        "    pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])\n",
        "    '''print('see')\n",
        "    print(all_embs.shape)\n",
        "    print(pool_embs.shape)'''\n",
        "    # pool_ebmbs is an embeding of CLS token\n",
        "    # all_embs contains embeding for words of input sentence.\n",
        "    return pool_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbicER-W-hs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BERTEmbeddings(model,tokenizer,nSentences):\n",
        "    trainX = np.asarray([])\n",
        "    n = len(nSentences)\n",
        "    for i in range(n): \n",
        "        if i%500 == 0:\n",
        "          print( 'Processing ',i,' out of ',n)\n",
        "\n",
        "        #senLen = len(nSentences[i].split())\n",
        "        embs = getEmbeddings(model,tokenizer,nSentences[i])\n",
        "        '''print(embs.shape)\n",
        "        x = embs'''\n",
        "        if trainX.shape[0] == 0:\n",
        "            trainX = embs\n",
        "        else:\n",
        "            trainX = np.concatenate((trainX, embs), axis=0)\n",
        "    return trainX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrGsWGrC3gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFileSent(inpFile):\n",
        "    fileSent = ''\n",
        "    article = ''\n",
        "    with open(inpFile,'r') as f:\n",
        "        x = json.loads(f.read())\n",
        "        article = x['article']\n",
        "        for option in x['options'][0]:\n",
        "            fileSent += option\n",
        "            fileSent += ' '\n",
        "        fileSent += x['questions'][0]\n",
        "    return fileSent,article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-LH0pLsCrBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getQuesEmb(model,tokenizer,inpFile):\n",
        "    fileSent,article = getFileSent(inpFile)\n",
        "    fileSent = fileSent + (' ' + fileSent)*5\n",
        "    emb = getEmbeddings(model,tokenizer,fileSent)\n",
        "    return emb,article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-EvJCcDczF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMatchingPara(quesEmb,paraEmbs):\n",
        "    #paraEmbs = np.loadtxt('paraEmbs.csv',delimiter=',')\n",
        "\n",
        "    scores = []\n",
        "    for paraEmb in paraEmbs:\n",
        "        score=float( cosine_similarity([paraEmb],[quesEmb]) )\n",
        "        scores.append(score)\n",
        "    print(scores)\n",
        "    mxScoreInd = scores.index(max(scores))\n",
        "    print(mxScoreInd)\n",
        "    mxScoreInd += 1\n",
        "\n",
        "    with open(paraFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      return x['para'+str(mxScoreInd)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTn8Iy2eFSxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveFile(inpFile,outFile,para):\n",
        "    with open(inpFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      x['article'] = para\n",
        "\n",
        "      with open(outFile, 'w') as jsonOut:\n",
        "          json.dump(x, jsonOut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c0JzBHG-Ea2",
        "colab_type": "text"
      },
      "source": [
        "# **Embedding Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsQXD44vAJL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outModel = getBERTModel()\n",
        "model = outModel['model']\n",
        "tokenizer = outModel['tokenizer']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6b70yI1-EKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(paraFile,'r')\n",
        "x = json.loads(f.read())\n",
        "f.close()\n",
        "fileSents = [ x['para'+str(id)] for id in range(1,len(x)+1)]\n",
        "#print(len(fileSents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfZPTzuiANKX",
        "colab_type": "code",
        "outputId": "29c8010f-bb1c-4fd2-d9e9-af4e34a30666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "paraEembs = BERTEmbeddings(model,tokenizer,fileSents)\n",
        "print(paraEembs.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing  0  out of  8\n",
            "(8, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdg7uHuSBD_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(basePath+'paraEmbs.csv',paraEembs, delimiter=',',fmt='%.15f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BuOVgIjBZpc",
        "colab_type": "code",
        "outputId": "3789fab5-5a6f-4795-d632-cfd15f0197c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''loaddata = np.loadtxt(basePath+'paraEmbs.csv', delimiter=',')\n",
        "print(loaddata[0])'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"loaddata = np.loadtxt(basePath+'paraEmbs.csv', delimiter=',')\\nprint(loaddata[0])\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_gOZwLkB5xs",
        "colab_type": "text"
      },
      "source": [
        "# **Generate Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VFdLK28B5AW",
        "colab_type": "code",
        "outputId": "08b36dc7-8e9d-4a6c-823f-f57d793fe357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "filenames = glob.glob(os.path.join(data_dir,'test')+\"/*json\")\n",
        "if not os.path.exists(outDir):\n",
        "    os.mkdir(outDir)\n",
        "count = 0\n",
        "for filename in filenames:\n",
        "    emb,article = getQuesEmb(model,tokenizer,filename)\n",
        "    print()\n",
        "    para = getMatchingPara(emb[0],paraEembs)\n",
        "    #print()\n",
        "    print(article)\n",
        "    print(para)\n",
        "    if article == para:\n",
        "        count += 1\n",
        "    name = filename.split('/')[-1]\n",
        "    #print(name)\n",
        "    saveFile(filename,os.path.join(outDir,name),para)\n",
        "\n",
        "print()\n",
        "print('accuracy: ',(count/len(filenames))*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[0.6284343004226685, 0.8486784100532532, 0.32978305220603943, 0.9308595657348633, 0.7500879764556885, 0.9169883728027344, 0.8644481897354126, 0.9163175821304321]\n",
            "3\n",
            "But transgenic animals just have one novel gene. What about an animal with a whole new genome? Could a clone , a genetically exact copy of an organism, be developed using techniques associated with biotechnology? It could be argued that human cloning is one of the inevitable outcomes of modern biotechnology. It \"simply\" involves the removal of the nucleus from a somatic cell and its placement into an unfertilized egg cell whose nucleus has either been deactivated or removed. This new cell would mimic the zygote, the first diploid cell of a new organism. This new zygote is allowed to become established, and a few days later is placed into the uterus of a surrogate mother. Theoretically this would result in an individual genetically identical to the donor. Obviously, there are many ethical and legal issues associated with human cloning, and of course, it is not a \"simple\" procedure. But animal cloning is arguably a different story.\n",
            "All radioactive decay is dangerous to living things, but alpha decay is the least dangerous.\n",
            "\n",
            "[0.7476679682731628, 0.8883669376373291, 0.5456182360649109, 0.8616126775741577, 0.8767240047454834, 0.9522082805633545, 0.820154070854187, 0.9635075330734253]\n",
            "7\n",
            "As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\n",
            "As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\n",
            "\n",
            "[0.6033649444580078, 0.7976741790771484, 0.3395853042602539, 0.8885735273361206, 0.76148521900177, 0.9029296636581421, 0.8077464699745178, 0.9087343215942383]\n",
            "7\n",
            "Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\n",
            "As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\n",
            "\n",
            "[0.6704493165016174, 0.7972476482391357, 0.522693395614624, 0.8059506416320801, 0.8640406727790833, 0.9211469292640686, 0.7360612154006958, 0.9399723410606384]\n",
            "7\n",
            "Figure 29.7 Vertebrata are characterized by the presence of a backbone, such as the one that runs through the middle of this fish. All vertebrates are in the Craniata clade and have a cranium. (credit: Ernest V. More; taken at Smithsonian Museum of Natural History, Washington, D.\n",
            "As you know, the surface of Earth is not flat. Some places are high, and some places are low. For example, mountain ranges like the Sierra Nevada in California or the Andes in South America are high above the surrounding areas. An accurate location must take into account the third dimension. Elevation is the height above or below sea level. Sea level refers to the height of the ocean’s surface. This is the midpoint between high and low tide. Sea level can vary from place to place, but scientists base their elevation measurements on the average, or mean, sea level to make sure they have a standard reference point.\n",
            "\n",
            "accuracy:  25.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Own6zheaEEaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile(basePath+'testdata.zip','w') as zf:\n",
        "    for dirname, subdirs, files in os.walk(outDir):\n",
        "        for filename in files:\n",
        "            zf.write(os.path.join(dirname.split('/')[-1], filename))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}