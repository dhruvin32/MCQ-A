{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genTestWithModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "echEDg9YGISz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input files: whole dataset, paragraphs file, addInfo Model\n",
        "# ouput: Zip file containing testing dataset with selected paragraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wxgmr3FHyFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAPmcP_5IDjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basePath = '/content/'\n",
        "\n",
        "data_dir = basePath+'dataset'\n",
        "drive_dir = basePath+'drive/My Drive/temp/DatasetN'\n",
        "paraFile = basePath + 'paragraph2.json'\n",
        "\n",
        "'''data_dir = basePath+'tempdataset'\n",
        "drive_dir = basePath+'drive/My Drive/temp/tempDataset'\n",
        "paraFile = basePath + 'temp.json' '''\n",
        "\n",
        "modelSave = basePath+'weights.pth'\n",
        "outDir = basePath+'test'\n",
        "alpha = 0.001\n",
        "embSize = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rznOey_YIGTs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4def61d4-04d7-481a-cea6-778d4d35fb0b"
      },
      "source": [
        "'''for file_name in os.listdir(drive_dir):\n",
        "    if file_name.endswith('.zip'):\n",
        "        with zipfile.ZipFile(drive_dir+'/'+file_name,'r') as zip_dir:\n",
        "            zip_dir.extractall(path='/content/')'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"for file_name in os.listdir(drive_dir):\\n    if file_name.endswith('.zip'):\\n        with zipfile.ZipFile(drive_dir+'/'+file_name,'r') as zip_dir:\\n            zip_dir.extractall(path='/content/')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx87MXrvIhiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sifEmbeddings(sentences, model, alpha):\n",
        "\n",
        "    vocab = model.wv.vocab\n",
        "    embs = model.wv       \n",
        "    size = model.vector_size  \n",
        "    \n",
        "    total = 0\n",
        "    for word in vocab:\n",
        "        total += vocab[word].count \n",
        "\n",
        "    output = []\n",
        "    \n",
        "    for sent in sentences:\n",
        "        count = 0\n",
        "        v = np.zeros(size, dtype=np.float32) \n",
        "        for word in sent:\n",
        "          if word in vocab:\n",
        "            #print(word)\n",
        "            weight = alpha / (alpha + (vocab[word].count/total))\n",
        "            v += weight * embs[word]\n",
        "            count += 1 \n",
        "                \n",
        "        if count > 0:\n",
        "            v *= 1/count\n",
        "\n",
        "        output.append(v)\n",
        "    return np.vstack(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9zQ_hBRIiYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitSent(sent):\n",
        "    regX = '[\\s()\\.\\?]'\n",
        "    splitSent = re.split(regX,sent)\n",
        "    splitSent = list(filter(None,splitSent))\n",
        "    return splitSent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWvpJO3sKvdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFileSent(inpFile):\n",
        "    fileSent = ''\n",
        "    article = ''\n",
        "    with open(inpFile,'r') as f:\n",
        "        x = json.loads(f.read())\n",
        "        article = x['article']\n",
        "        '''for option in x['options'][0]:\n",
        "            fileSent += option\n",
        "            fileSent += ' ' '''\n",
        "        fileSent += x['questions'][0]\n",
        "    return fileSent,article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LORqWKGuImj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDatasetAsSents():\n",
        "    fileSents = []\n",
        "    dirs = os.listdir(data_dir)\n",
        "    print(dirs)\n",
        "    for d in dirs:\n",
        "      filenames = glob.glob(os.path.join(data_dir,d)+\"/*json\")\n",
        "      for file in filenames:\n",
        "          with open(file,'r') as f:\n",
        "              x = json.loads(f.read())\n",
        "              for option in x['options'][0]:\n",
        "                  fileSents.append(option)\n",
        "              fileSents.append(x['questions'][0])\n",
        "              fileSents.append(x['article'])\n",
        "    return fileSents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImaWzEEGJ312",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getQuesEmb(model,inpFile):\n",
        "    fileSent,article = getFileSent(inpFile)\n",
        "    #fileSent = fileSent + (' ' + fileSent)*5\n",
        "    sent = splitSent(fileSent)\n",
        "    emb = sifEmbeddings([sent], model, alpha=alpha)[0]\n",
        "    return emb,article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMUsM0CKibu",
        "colab_type": "code",
        "outputId": "1d7e1597-27a0-4e35-a26b-05a8a1cd0d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''def getMatchingPara(quesEmb,paraEmbs):\n",
        "    #paraEmbs = np.loadtxt('paraEmbs.csv',delimiter=',')\n",
        "\n",
        "    scores = []\n",
        "    for paraEmb in paraEmbs:\n",
        "        score=float( cosine_similarity([paraEmb],[quesEmb]) )\n",
        "        scores.append(score)\n",
        "    #print(scores)\n",
        "    mxScoreInd = scores.index(max(scores))\n",
        "    mxScoreInd += 1\n",
        "\n",
        "    with open(paraFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      return x['para'+str(mxScoreInd)]'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def getMatchingPara(quesEmb,paraEmbs):\\n    #paraEmbs = np.loadtxt('paraEmbs.csv',delimiter=',')\\n\\n    scores = []\\n    for paraEmb in paraEmbs:\\n        score=float( cosine_similarity([paraEmb],[quesEmb]) )\\n        scores.append(score)\\n    #print(scores)\\n    mxScoreInd = scores.index(max(scores))\\n    mxScoreInd += 1\\n\\n    with open(paraFile,'r') as f:\\n      x = json.loads(f.read())\\n      return x['para'+str(mxScoreInd)]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xst8H5QiRhqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMatchingPara(quesEmb,paraEmbs):\n",
        "    #paraEmbs = np.loadtxt('paraEmbs.csv',delimiter=',')\n",
        "\n",
        "    scores = []\n",
        "    for paraEmb in paraEmbs:\n",
        "        score=float( cosine_similarity([paraEmb],[quesEmb]) )\n",
        "        scores.append(score)\n",
        "    #print(scores)\n",
        "    #mxScoreInd = scores.index(max(scores))\n",
        "    #mxScoreInd += 1\n",
        "    topK = 3\n",
        "    #a = [2,6,5,9,7,2,3,6]\n",
        "    topIds = np.argsort(scores)[-topK:]\n",
        "    topIds += 1\n",
        "    #topVal = [scores[i] for i in topIds]\n",
        "\n",
        "    with open(paraFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      for id in topIds:\n",
        "          print(x['para'+str(id)])\n",
        "      return x['para'+str(topIds[-1])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjJHFu6xK-mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveFile(inpFile,outFile,para):\n",
        "    with open(inpFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      x['article'] = para\n",
        "\n",
        "      with open(outFile, 'w') as jsonOut:\n",
        "          json.dump(x, jsonOut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHnQTD-9Ot2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model():\n",
        "    model = nn.Sequential(  nn.Linear(embSize,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,embSize)\n",
        "                            \n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDIGcml7shcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def restorModel():\n",
        "    addInfoModel = initialize_model()\n",
        "    addInfoModel.load_state_dict(torch.load(modelSave))\n",
        "    addInfoModel.eval()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    addInfoModel = addInfoModel.to(device)\n",
        "    return addInfoModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDg6FWqixG1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getInfoEmb(model,emb):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tensorEmb = torch.from_numpy(np.expand_dims(emb, axis=0)).to(device)\n",
        "    outEmb = model(tensorEmb)\n",
        "    qusEmb = outEmb.detach().cpu().numpy()[0]\n",
        "    return qusEmb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygrHSz5AIuFE",
        "colab_type": "text"
      },
      "source": [
        "# **Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnmbqavSIxN0",
        "colab_type": "code",
        "outputId": "75f76612-f760-40ff-e452-227763c8e176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fileSents = getDatasetAsSents()\n",
        "sentences = [ splitSent(sent) for sent in fileSents]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['dev', 'train', 'test']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABqmU7Z5I0Qc",
        "colab_type": "code",
        "outputId": "1f09c42a-f3df-4543-8e34-947b61f55b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = Word2Vec(sentences, min_count=1, size=embSize)\n",
        "model.save(basePath+\"word2vec.model\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NHoGYHNJHhk",
        "colab_type": "text"
      },
      "source": [
        "# **Embedding Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd3hWlWHJHJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(paraFile,'r')\n",
        "x = json.loads(f.read())\n",
        "f.close()\n",
        "fileSents = [ x['para'+str(id)] for id in range(1,len(x)+1)]\n",
        "sentences = [ splitSent(sent) for sent in fileSents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd3S3hfLJam8",
        "colab_type": "code",
        "outputId": "6e3437bb-3c08-49d3-8e7b-445f2a443fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#model = Word2Vec.load(\"word2vec.model\")\n",
        "paraEembs = sifEmbeddings(sentences, model, alpha=alpha)\n",
        "print(paraEembs.shape)\n",
        "#np.savetxt(basePath+'paraEmbs.csv',paraEembs, delimiter=',',fmt='%.15f')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12304, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLYEbbeHJn8c",
        "colab_type": "text"
      },
      "source": [
        "# **Generate Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqsO3SBdQWJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "addInfoModel = restorModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKkcu-KJm7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = glob.glob(os.path.join(data_dir,'test')+\"/*json\")\n",
        "\n",
        "\n",
        "if not os.path.exists(outDir):\n",
        "    os.mkdir(outDir)\n",
        "count = 0\n",
        "ind = 0\n",
        "for filename in filenames:\n",
        "    if ind == 20:\n",
        "      break\n",
        "    emb,article = getQuesEmb(model,filename)\n",
        "    '''tensorEmb = torch.from_numpy(np.expand_dims(emb, axis=0)).to(device)\n",
        "    outEmb = addInfoModel(tensorEmb)\n",
        "    qusEmb = outQusEmb.detach().cpu().numpy()[0]'''\n",
        "    qusEmb = getInfoEmb(addInfoModel,emb)\n",
        "    #print(qusEmb.shape)\n",
        "    #dataloader = getDataLoaders(emb)\n",
        "    #print(dataloader)\n",
        "    #break\n",
        "\n",
        "    print()\n",
        "    para = getMatchingPara(qusEmb,paraEembs)\n",
        "    #print()\n",
        "    print(article)\n",
        "    #print(para)\n",
        "    if article == para:\n",
        "        count += 1\n",
        "    name = filename.split('/')[-1]\n",
        "    #print(name)\n",
        "    saveFile(filename,os.path.join(outDir,name),para)\n",
        "    ind += 1\n",
        "\n",
        "print()\n",
        "print('accuracy: ',(count/len(filenames))*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElSeTc-WM9z1",
        "colab_type": "code",
        "outputId": "05268efa-a4f8-4a97-80bb-6032eaeb5f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''with zipfile.ZipFile(basePath+'testdata.zip','w') as zf:\n",
        "    for dirname, subdirs, files in os.walk(outDir):\n",
        "        for filename in files:\n",
        "            zf.write(os.path.join(dirname.split('/')[-1], filename))'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"with zipfile.ZipFile(basePath+'testdata.zip','w') as zf:\\n    for dirname, subdirs, files in os.walk(outDir):\\n        for filename in files:\\n            zf.write(os.path.join(dirname.split('/')[-1], filename))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}