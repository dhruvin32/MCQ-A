{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AddInfo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NruyZ7kcmNkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input files: embedding file in CSV formate(odd index contain question embeddings, even index contains paragraph embeddings)\n",
        "# Output files: weights.pth --> trained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxAFGAbJWOJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ35vyVIpg-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basePath = '/content/'\n",
        "\n",
        "modelSave = basePath+'weights.pth'\n",
        "trainFile = basePath+'temp.csv'\n",
        "testFile = basePath+'temp.csv'\n",
        "\n",
        "learning_rate = 0.0001\n",
        "batch_size = 8\n",
        "num_epochs = 2\n",
        "input_dim = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oroq2d4A6r9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0WgQUsYl_rl",
        "colab_type": "code",
        "outputId": "3b83a643-9543-4ece-fb9f-c6f28513b424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''import zipfile\n",
        "import os\n",
        "for file_name in os.listdir('/content/'):\n",
        "  if file_name.endswith('.zip'):\n",
        "    with zipfile.ZipFile(file_name,'r') as zip_dir:\n",
        "      zip_dir.extractall(path='/content/')'''"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"import zipfile\\nimport os\\nfor file_name in os.listdir('/content/'):\\n  if file_name.endswith('.zip'):\\n    with zipfile.ZipFile(file_name,'r') as zip_dir:\\n      zip_dir.extractall(path='/content/')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c780N2trIg24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inpEmbs, outEmbs in dataloaders:\n",
        "            inpEmbs = inpEmbs.to(device)\n",
        "            outEmbs = outEmbs.to(device)\n",
        "            '''print(inpEmbs.shape)\n",
        "            print(outEmbs.shape)'''\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                # Get model outputs and calculate loss\n",
        "                outputs = model(inpEmbs)\n",
        "                loss = criterion(outputs,outEmbs)\n",
        "\n",
        "                # backward + optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inpEmbs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
        "        print('Loss: {:.4f}'.format(epoch_loss))\n",
        "        history.append(epoch_loss)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    return model,history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diQy1uibWAUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model():\n",
        "    model = nn.Sequential(  nn.Linear(input_dim,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,input_dim)\n",
        "                            \n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekvly_gT6WWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDataLoaders(path):\n",
        "    dataload = np.loadtxt(path, delimiter=',')\n",
        "    quesEmb = torch.tensor(dataload[::2], dtype=torch.float)\n",
        "    paraEmb = torch.tensor(dataload[1::2], dtype=torch.float)\n",
        "    print(quesEmb.shape)\n",
        "    print(paraEmb.shape)\n",
        "\n",
        "    eval_data = TensorDataset(quesEmb, paraEmb)\n",
        "    eval_sampler = SequentialSampler(eval_data)\n",
        "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)\n",
        "    return eval_dataloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNhuHlIf7C3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUpdatablePara(model):\n",
        "    params_to_update = model.parameters()\n",
        "    print(\"Params to learn:\")\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "        if  param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            #print(\"\\t\",name)\n",
        "    return params_to_update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ0yjGxS_kF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testModel(model, dataloaders, criterion):\n",
        "    running_loss = 0\n",
        "    for inpEmbs, outEmbs in dataloaders:\n",
        "        inpEmbs = inpEmbs.to(device)\n",
        "        outEmbs = outEmbs.to(device)\n",
        "\n",
        "        outputs = model(inpEmbs)\n",
        "        loss = criterion(outputs,outEmbs)\n",
        "\n",
        "        running_loss += loss.item() * inpEmbs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders.dataset)\n",
        "    print('Loss: {:.5f}'.format(epoch_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwYabkKX7oR_",
        "colab_type": "text"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWWsdyCJJFxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= initialize_model()\n",
        "model = model.to(device)\n",
        "#print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97r-6fJpJB7x",
        "colab_type": "code",
        "outputId": "c3709f7b-1485-4445-8a39-04ef4c065bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataloaders = getDataLoaders(trainFile)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 200])\n",
            "torch.Size([4, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwUX-7c4IupU",
        "colab_type": "code",
        "outputId": "5fed2e09-da47-4610-afc3-23cd6ca81880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params_to_update = getUpdatablePara(model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtz6hjnpU_IY",
        "colab_type": "code",
        "outputId": "435082eb-8239-4a3b-db32-88274dbc1511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)\n",
        "\n",
        "#loss function\n",
        "criterion = nn.MSELoss()\n",
        "#criterion = nn.MSELoss(reduction='sum')\n",
        "\n",
        "trainedModel, hist = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)\n",
        "\n",
        "torch.save(trainedModel.state_dict(), modelSave)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/1\n",
            "----------\n",
            "Loss: 0.3035\n",
            "Epoch 1/1\n",
            "----------\n",
            "Loss: 0.2996\n",
            "Training complete in 0m 0s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJSLOhpV7t34",
        "colab_type": "text"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZtBBKp7yDY",
        "colab_type": "code",
        "outputId": "bd0abd4b-a9d0-4e48-dc5f-24b52b786bef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = initialize_model()\n",
        "\n",
        "model.load_state_dict(torch.load(modelSave))\n",
        "model.eval()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "dataloaders = getDataLoaders(testFile)\n",
        "criterion = nn.MSELoss()\n",
        "testModel(model,dataloaders,criterion)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 200])\n",
            "torch.Size([4, 200])\n",
            "Loss: 0.00048\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}