{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getTestBERTwithModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PPWzIEMCWyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input files: test dataset or whole dataset,paragraphs file, addInfo model\n",
        "# ouput: Zip file containing testing dataset with selected paragraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFWrvC3hRSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''!pip install tensorflow-gpu==2.0\n",
        "!pip install tensorflow_hub\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghxYM2BH9Vq6",
        "colab_type": "code",
        "outputId": "769e6165-3016-42f9-e24b-5df603f69169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.0.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Y0nbeK9Xl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
        "#import math\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7AlViAd9ahm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basePath = '/content/'\n",
        "\n",
        "data_dir = basePath+'dataset'\n",
        "drive_dir = basePath+'drive/My Drive/temp/DatasetN'\n",
        "paraFile = basePath + 'paragraph2.json'\n",
        "\n",
        "'''data_dir = basePath+'tempdataset'\n",
        "drive_dir = basePath+'drive/My Drive/temp/tempDataset'\n",
        "paraFile = basePath + 'temp.json' '''\n",
        "\n",
        "modelSave = basePath+'bert_weights_sum_800.pth'\n",
        "outDir = basePath+'test'\n",
        "\n",
        "embSize = 768\n",
        "max_seq_length = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9GmAOEr9hR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''for file_name in os.listdir(drive_dir):\n",
        "    if file_name.endswith('.zip'):\n",
        "        with zipfile.ZipFile(drive_dir+'/'+file_name,'r') as zip_dir:\n",
        "            zip_dir.extractall(path='/content/')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL4bVRKh9jwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getBERTModel():\n",
        "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_mask\")\n",
        "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"segment_ids\")\n",
        "\n",
        "    bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=False)\n",
        "    #bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\",trainable=False)\n",
        "    \n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])\n",
        "\n",
        "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "    FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "    tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "    return {'model':model,'tokenizer':tokenizer}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTZ-xWWW9mHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_masks(tokens, max_seq_length):\n",
        "    #print('len(tokens),max_seq_length)\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbY_RPO9orm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getEmbeddings(model,tokenizer,sentence): \n",
        "    stokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    if len(stokens) > (max_seq_length - 2):\n",
        "      stokens = stokens[:max_seq_length-2]\n",
        "\n",
        "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
        "    #print(len(input_ids))\n",
        "    input_masks = get_masks(stokens, max_seq_length)\n",
        "    input_segments = get_segments(stokens, max_seq_length)\n",
        "\n",
        "    '''print(input_masks)\n",
        "    print(input_segments)'''\n",
        "\n",
        "    pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])\n",
        "    '''print('see')\n",
        "    print(all_embs.shape)\n",
        "    print(pool_embs.shape)'''\n",
        "    # pool_ebmbs is an embeding of CLS token\n",
        "    # all_embs contains embeding for words of input sentence.\n",
        "    return pool_embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbicER-W-hs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BERTEmbeddings(model,tokenizer,nSentences):\n",
        "    trainX = np.asarray([])\n",
        "    n = len(nSentences)\n",
        "    for i in range(n): \n",
        "        if i%500 == 0:\n",
        "          print( 'Processing ',i,' out of ',n)\n",
        "\n",
        "        #senLen = len(nSentences[i].split())\n",
        "        embs = getEmbeddings(model,tokenizer,nSentences[i])\n",
        "        '''print(embs.shape)\n",
        "        x = embs'''\n",
        "        if trainX.shape[0] == 0:\n",
        "            trainX = embs\n",
        "        else:\n",
        "            trainX = np.concatenate((trainX, embs), axis=0)\n",
        "    return trainX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrGsWGrC3gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFileSent(inpFile):\n",
        "    fileSent = ''\n",
        "    article = ''\n",
        "    with open(inpFile,'r') as f:\n",
        "        x = json.loads(f.read())\n",
        "        article = x['article']\n",
        "        for option in x['options'][0]:\n",
        "            fileSent += option\n",
        "            fileSent += ' '\n",
        "        fileSent += x['questions'][0]\n",
        "    return fileSent,article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-LH0pLsCrBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getQuesEmb(model,tokenizer,inpFile):\n",
        "    fileSent,article = getFileSent(inpFile)\n",
        "    fileSent = fileSent + (' ' + fileSent)*5\n",
        "    emb = getEmbeddings(model,tokenizer,fileSent)\n",
        "    return emb,article"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US-EvJCcDczF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMatchingPara(quesEmb,paraEmbs):\n",
        "    #paraEmbs = np.loadtxt('paraEmbs.csv',delimiter=',')\n",
        "\n",
        "    scores = []\n",
        "    for paraEmb in paraEmbs:\n",
        "        score=float( cosine_similarity([paraEmb],[quesEmb]) )\n",
        "        scores.append(score)\n",
        "    print(scores)\n",
        "    mxScoreInd = scores.index(max(scores))\n",
        "    print(mxScoreInd)\n",
        "    mxScoreInd += 1\n",
        "\n",
        "    with open(paraFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      return x['para'+str(mxScoreInd)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTn8Iy2eFSxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveFile(inpFile,outFile,para):\n",
        "    with open(inpFile,'r') as f:\n",
        "      x = json.loads(f.read())\n",
        "      x['article'] = para\n",
        "\n",
        "      with open(outFile, 'w') as jsonOut:\n",
        "          json.dump(x, jsonOut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S90H4CpDvG0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_model():\n",
        "    model = nn.Sequential(  nn.Linear(embSize,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,1024),\n",
        "                            nn.ReLU(),\n",
        "                            nn.BatchNorm1d(1024),\n",
        "                          \n",
        "                            nn.Linear(1024,embSize)\n",
        "                            \n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMHFMs5CvIkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def restorModel():\n",
        "    addInfoModel = initialize_model()\n",
        "    addInfoModel.load_state_dict(torch.load(modelSave))\n",
        "    addInfoModel.eval()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    addInfoModel = addInfoModel.to(device)\n",
        "    return addInfoModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afLFA7IFvKIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getInfoEmb(model,emb):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    tensorEmb = torch.from_numpy(np.expand_dims(emb, axis=0)).to(device)\n",
        "    outEmb = model(tensorEmb)\n",
        "    qusEmb = outEmb.detach().cpu().numpy()[0]\n",
        "    return qusEmb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c0JzBHG-Ea2",
        "colab_type": "text"
      },
      "source": [
        "# **Embedding Generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsQXD44vAJL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outModel = getBERTModel()\n",
        "model = outModel['model']\n",
        "tokenizer = outModel['tokenizer']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6b70yI1-EKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(paraFile,'r')\n",
        "x = json.loads(f.read())\n",
        "f.close()\n",
        "fileSents = [ x['para'+str(id)] for id in range(1,len(x)+1)]\n",
        "#print(len(fileSents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfZPTzuiANKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paraEembs = BERTEmbeddings(model,tokenizer,fileSents)\n",
        "print(paraEembs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdg7uHuSBD_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(basePath+'paraEmbs.csv',paraEembs, delimiter=',',fmt='%.15f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BuOVgIjBZpc",
        "colab_type": "code",
        "outputId": "3789fab5-5a6f-4795-d632-cfd15f0197c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''loaddata = np.loadtxt(basePath+'paraEmbs.csv', delimiter=',')\n",
        "print(loaddata[0])'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"loaddata = np.loadtxt(basePath+'paraEmbs.csv', delimiter=',')\\nprint(loaddata[0])\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_gOZwLkB5xs",
        "colab_type": "text"
      },
      "source": [
        "# **Generate Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AUFXSdNvbka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "addInfoModel = restorModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VFdLK28B5AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = glob.glob(os.path.join(data_dir,'test')+\"/*json\")\n",
        "if not os.path.exists(outDir):\n",
        "    os.mkdir(outDir)\n",
        "count = 0\n",
        "ind = 0\n",
        "for filename in filenames:\n",
        "    if ind == 100:\n",
        "      break\n",
        "    ind = ind + 1\n",
        "    emb,article = getQuesEmb(model,tokenizer,filename)\n",
        "    qusEmb = getInfoEmb(addInfoModel,emb[0])\n",
        "    print()\n",
        "    para = getMatchingPara(qusEmb,paraEembs)\n",
        "    #print()\n",
        "    print(article)\n",
        "    print(para)\n",
        "    if article == para:\n",
        "        count += 1\n",
        "    name = filename.split('/')[-1]\n",
        "    #print(name)\n",
        "    saveFile(filename,os.path.join(outDir,name),para)\n",
        "\n",
        "print()\n",
        "print('accuracy: ',(count/len(filenames))*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Own6zheaEEaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile(basePath+'testdata.zip','w') as zf:\n",
        "    for dirname, subdirs, files in os.walk(outDir):\n",
        "        for filename in files:\n",
        "            zf.write(os.path.join(dirname.split('/')[-1], filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WIieTFW6649",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(\"temp\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}